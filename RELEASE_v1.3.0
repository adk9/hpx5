HPX–5 Version 1.3.0 Release Notes
---------------------------------

Release date: 09/22/2015

Distributed under the Indiana University License.
(See accompanying file COPYING.txt) 

HPX-5 (High Performance ParalleX) provides a unified programming model
for parallel and distributed applications. It is freely available,
open source, feature complete, and performance-oriented implementation
of the ParalleX execution model. HPX-5 is a general-purpose C runtime
system for applications, targeted at conventional, widely available
architectures. We use HPX-5 for a broad range of scientific
applications, helping scientists and developers to write code that
shows better performance on irregular applications and at scale when
compared to more conventional programming models such as MPI. HPX-5
supports such applications with implementation of features like Active
Global Address Space (AGAS), ParalleX Processes, Complexes (ParalleX
Threads and Thread Management), Parcel Transport and Parcel
Management, Local Control Objects (LCOs) and Localities.

General Information
---------------------

If you plan to use HPX–5, we suggest starting with the latest released
version (currently HPX–5 v1.3.0) which can be downloaded from
https://hpx.crest.iu.edu/download. If you would like to work with the
cutting edge version of HPX–5, we suggest using the the `develop`
branch at https://gitlab.crest.iu.edu/extreme/hpx. While we try to
keep the develop branch stable and usable, sometimes new bugs trick
their way into the code base - be aware!

Documentation for the latest release of HPX–5 (currently v1.3.0) and
the previous versions can be accessed at
https://hpx.crest.iu.edu/documentation. The FAQ can be found at
https://hpx.crest.iu.edu/faqs_and_tutorials.

If you would like to work with the cutting edge version of HPX–5, we
suggest following the current health status of the develop branch at
https://gitlab.crest.iu.edu/extreme/hpx. While we try to keep the 
develop branch stable and usable, sometimes new bugs trick their way
into the code base - be aware!

Build Instructions
------------------

The detailed build instructions can be found at
[https://hpx.crest.iu.edu/faqs_and_tutorials] or
[https://hpx.crest.iu.edu/Users_Guide]. 

What's new in HPX–5 v1.3.0?
----------------------------

1. Added the hpx-config script, which provides information about how
HPX–5 was configured, and how to integrate it into application
builds. 

2. Implemented the steal-last scheduler optimization. This scheduler
optimization makes a worker remember the victim that it last stole
from successfully, and tries to steal from it again. If no work is
found, it goes back to random stealing until a worker is found that it
is successfully able to steal from. For a carefully engineered
use-case in parbench, where an action affinitized to a core generates
work periodically, this seems to marginally reduce the number of
failed steals. We expect such a scenario to be more common in the
distributed case where a large chunk of non-local work periodically
shows up at the network thread.

3. Added compound hpx_lco_wait_reset and hpx_lco_get_reset
operations. This compound atomic operation reduces the number of
locks, and-or messages, required. It is implemented in both local and
rendevous-remote form. Also upgraded remote lco_wait operations to use
scheduler_suspend.

4. We have added interfaces for allreduce_join.

5. We have re-enabled hwloc support. Use --with-hwloc=contrib.

6. Added general performance counters (including timing) interface for
both with and without PAPI support.

7. Photon now dynamically adjusts Verbs num_cq if needed for a given
allocation.

8. Photon includes updated remote completion support for uGNI and
Verbs backends, improving probe performance as node counts scale
beyond 1k.

API Changes: Improvements/Enhancements
---------------------------------------

1. Added hpx_lco_delete_sync to delete an LCO synchronously.

2. hpx_finalize() is a new function which must be called between the
last call to hpx_run() and the end of the program.

3. hpx_exit() has replaced hpx_shutdown(). Its usage for now is the
same as the usage of hpx_shutdown(). (In future releases it will be
possible to call it multiple times per program (once each for each
call to hpx_run()).)

4. We have extended the LCO interface with compound
hpx_lco_get_reset() and hpx_lco_wait_reset() operations. These can
eliminate timing windows and improve performance when this is the
required semantics.

5. We have extended the allreduce LCO interface with a set of
asynchronous hpx_lco_allreduce_join() operations. These are much lower
overhead than the native LCO set()/get() alternative and should be
preferred when possible.

6. hpx_time_diff_ns() now returns an int64_t instead of an uint64_t,
to allow for negative intervals.

7. uint64_t hpx_time_elapsed_ns(hpx_time_t from); has been added to
match the existing functions for other time resolutions
(hpx_time_elapsed_us(), etc.). It will return the time elapsed from
some point in the past to when the function is called.

8. We have replaced the --hpx-dbg-waitonsegv option with a general
purpose --hpx-dbg-waitonsig option, that allows users to select sets
of signals to wait on.

9. We have allowed allreduce to have no value. In this context it acts
as an inefficient barrier.

10. We have upgraded jemalloc to 4.0.2 and pulled in latest libcuckoo
changes.
	
Removed/Retired Features
---------------------------

1. dlmalloc is removed from this release.

Bug Fixes
------------

1. hpx_time_diff_ns() is now implemented.

2. Get hpx_threads on cray systems from ALPS_APP_DEPTH.

3. CPU_COUNT is no longer required.

Application Updates
-----------------------

The "parcels" version of the LULESH application has been cleaned up
and updated to use autoconf. The --enable-serial-recv option reduces
available parallelism, but can increase performance by being smarter
about locality. Overall performance improvements to the app and HPX-5
have increased the scalability of LULESH somewhat. Prefer tbbmalloc
for LULESH where available.

Known bugs & limitations in the release
----------------------------------------

1. While with the current API it is intended that hpx_run() may now be
called multiple times within a single program, at present it is not
possible to call hpx_run() multiple times.

2. HPX–5 on MAC only builds with default xcode toolchain that comes
with MAC $ ./configure --with-hwloc=contrib CC=clang, gcc installed
with brew or port is not supported. We believe this is due to
https://gcc.gnu.org/bugzilla/show_bug.cgi?format=multiple&id=60893.

3. AGAS and TBBMalloc require a C++11 compiler.

4. The AGAS implementation only works with the Isend/Irecv network,
and is still considered experimental.

5. Clang versions prior to 3.6 (3.5.1 and earlier) contain regressions
that trigger runtime failures in HPX.

6. Cray support is experimental. To run an HPX—5 application, use
aprun -n [nodes] -N 1 -d [ppn] ./app. The d option controls the number
of threads per locality, it can be overridden with
--hpx-threads. HPX–5 cannot be compiled using craycc.

7. The SSSP variants (delta-stepping, distributed-control, KLA) in
libPXGL are experimental and are unlikely to run successfully at
larger scales.

8. HPX–5 only runs with 1 thread by default on Jetson boards.

9. HPX_THREAD_CONTINUE does not run C++ destructors.

10. Linking tests/examples/tutorials --with-apex when apex is built
statically fails.

11. LULESH induces a performance regression with jemalloc, prefer
tbbmalloc for it. Also use hugetlbfs when available.

12. Blocked distribution is unimplemented.

13. Remote hpx_lco_get/wait operations do not propagate errors
correctly.

14. Photon CQ overrun warning is generated for large uGNI
allocations. Can be safely ignored for most jobs.

More information
-------------------

Build Instructions
====================
The detailed build instructions can be found at 
https://hpx.crest.iu.edu/faqs_and_tutorials or 
https://hpx.crest.iu.edu//Users_Guide. 

Reporting bugs
====================
In any case, if you happen to run into problems we very much encourage and
appreciate issue reports through the issue tracker for this Gitlab project 
(https://gitlab.crest.iu.edu/extreme/hpx/issues).  

Participate in HPX–5
=====================
If you would like to help shape HPX–5, take a look at the list of ways you
can participate at http://hpx.crest.iu.edu/get-involved.

More about HPX–5
====================
For more information about HPX–5, including information about the latest 
release, please check out the main http://hpx.crest.iu.edu/about. If you 
have questions or comments, the HPX–5 Developer’s Mailing List is a good
place to send them.

Subscribe your e-mail address to be notified when new releases of HPX–5 
are released using the mailing list: HPX–5 Announcements List 
http://www.crest.iu.edu/mailman/listinfo.cgi/hpx-announce.
