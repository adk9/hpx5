HPX Release notes, Version 0.6.0
=====================================
Release date: 04/01/2015

Distributed under the License, Version 0.6.0. (See accompanying file LICENSE_0.6.0.txt)

New features
===================
1. HPX relies on the launcher (aprun/mpirun) to set affinity and number of cores per locality.
2. Pinned actions receive the parcel's translated local target through a parameter.
3. All of the LCOs can be allocated in arrays.
4. Add synchronous interface for LCO reset.
5. lco_get_all() and lco_wait_all() now permit HPX_NULL addresses
   - This is primarily a convenience to make code simpler to write.
6. Added hpx_call_when_with_cc() function
   - This allows users to delay the current continuation until a condition has become true, without needing to block the current thread, in cases where that makes sense.
7. The hpx_gas_memget() and hpx_gas_memput() now use RDMA get/put where appropriate and available.
   - The local side of the get/put must be from network registered memory.
   - Stacks and parcels are registered implicitly.
   - Statics, globals, and stdlib malloc/calloc/etc. are dynamically registered.
8. Added --hpx-help flag to dump HPX's usage output.
9. hpx_lco_delete_all(n, lcos[n], hpx_addr_t sync) can be used to delete an array of LCOs.
10. Updated the GAS interface (see API Changes)
   - GAS allocation provides alignment options.
   - Added an interface for allocating memory "At" a locality.
   - Unified local and global allocations.
   - Added GAS distributions.

API Changes
==================
1. hpx_thread_current_local_target() is now deprecated. Now HPX translates the target address and passes it as an argument to the action. If your code uses a pinned action, then an action such as the following:

static HPX_PINNED(foo, void *arg) { 
void *local = hpx_thread_current_local_target(); 
... 
}
changes to:

static HPX_PINNED(foo, void *local, void *arg) { 
... 
}

2. The interface for global memory allocation has changed in the following ways:
  - Renamed hpx_gas_global_{c,}alloc to hpx_gas_{c,}alloc_cyclic
  - Renamed hpx_gas_{c,}alloc to hpx_gas_{c,}alloc_local
  - Introduced hpx_gas_{c,}alloc_blocked for super-block-cyclic allocations
  - Introduced hpx_gas_{c,}alloc() for allocating with a user-specified GAS distribution type.
  - Eliminated hpx_gas_memalign, and added a boundary argument to the allocation interface to specify an alignment for the allocation.

Improvements/Enhancements
==============================
1. Improved pwc() network implementation for parcel transport
2. Refactored pwc network to reduce unused or overly complex code
3. parcel structure refactoring
   - PWC eager parcels are now block allocated
4. Pruned outdated transport code
5. Jenkins CI
   - Tests compilation with clang and intel icc compiler.
   - Set up on Stampede and Edison.
6. Parcels can be "retained" when we want their buffer to persist.
   - This is equivalent to one-bit reference counting and is used to optimize call_when/send_through

Removed/Retired Features
==============================
1. libffi custom structure and array functionality removed

Deprecated
===================
1. The netfutures infrastructure is deprecated.
2. The channel LCO is deprecated.
3. The --hpx-cores option is deprecated, use aprun -d N and mpirun --map-by node=PE:N instead.

Bug Fixes
====================
1. Allreduce and other collective LCOs support call_when/parcel_send_through
2. Reduce LCO is now resettable
3. The and LCO now uses fast atomic operations again
4. ugni is set as default photon backend when enabled
5. Fixed guppie example
6. Support large stack use in main() before the call to hpx_run()
7. No longer serialize to assign parcels ids during instrumentation
8. Do not explicitly set affinity
  - This eliminates large startup skew on Cray systems
9. Added get ref/reduce handlers for LCO reduce.

Build Instructions
=========================
The detailed build instructions can be found at README or Getting started with HPX Runtime Systems in the docs folder.

Known bugs & limitations
==========================
1. Clang-3.5.1 and earlier regressions trigger runtime failures
2. HPX v0.6.0 is not tested with ARM.
3. Cray support is experimental (use aprun -n [nodes] -N 1 -d [ppn] ./app).
4. perf_lco_netfutures_msgsize runs slowly on isir/pwc.
5. Some tutorials use deprecated HPX interfaces.
6. Generation counters fail for ninplace > 0.
7. The ISIR network with OpenMPI 1.8.4 and MTL for Mellanox may deadlock in the opal allocation routines during large parcel (rendezvous) sends.

Results
=========================

Acknowledgements
=========================
* DOD BIG: Title: Advanced Development of the DoD Extreme-scale Execution Framework
Acknowledgment: no specific clause is needed; subcontractor must indicate "PO #190, Task Order #002, Project #BY11-034SP" on all invoices and other communications for work performed under the terms of this subcontract.
* PSAAP: "This material is based upon work supported by the Department of Energy, National Nuclear Security Administration, under Award Number(s) DE-NA0002377."             The Centers involved include:
     1. Center for Research in Extreme Scale Technologies (CREST), Indiana University
     2. Center for Shock-Wave Processing of Advanced Reactive Materials, University of Notre Dame
* XPRESS: XPRESS
Title: eXascale PRogramming Environment and System Software (XPRESS)
Acknowledgment: "This material is based upon work supported by the Department of Energy under Award Number(s) DE-SC0008809."
Disclaimer: "This report was prepared as an account of work sponsored by an agency of the United States Government. Neither the United States Government nor any agency thereof, nor any of their employees, makes any warranty, express or implied, or assumes any legal liability or responsibility for the accuracy, completeness, or usefulness of any information, apparatus, product, or process disclosed, or represents that its use would not infringe privately owned rights. Reference herein to any specific commercial product, process, or service by trade name, trademark, manufacturer, or otherwise does not necessarily constitute or imply its endorsement, recommendation, or favoring by the United States Government or any agency thereof. The views and opinions of authors expressed herein do not necessarily state or reflect those of the United States Government or any agency thereof."
* XSEDE computer time grant TG-CCR140035 "Dynamic Introspective Runtime to Enable Extreme Scaling for Irregular Time-varying Problems‚Äù.
This work used the Extreme Science and Engineering Discovery Environment (XSEDE), which is supported by National Science Foundation grant number ACI-1053575.
