HPX–5 Version 4.0.0 Release Notes
---------------------------------

Release date: 11/01/2016

Distributed under the Indiana University License.
(See accompanying file LICENSE.txt) 

HPX-5 is the High Performance ParalleX runtime library, a state-of-the-art 
runtime system from the Center for Research in Extreme Scale Technology (CREST) 
at Indiana University for exascale-scale computing. HPX-5 employs dynamic and 
adaptive resource management and task scheduling to achieve the significant 
improvements in efficiency and scalability necessary to deploy many classes of 
parallel applications at exascale. Although still under development, HPX-5 
supports a diverse set of systems, is reliable and programmable, is scalable 
across multi-core and multi-node systems, and delivers efficiency improvements 
for irregular, time-varying problems. HPX-5 is a realization of ParalleX, an 
abstract crosscutting execution model, which establishes the runtime's roles 
and responsibilities with respect to other interoperating system layers, and is 
evaluated within the SLOWER performance model that provide a framework for 
performance, understanding, and optimization.

HPX-5 is a reduction to practice of the revolutionary ParalleX execution model, 
which establishes roles and responsibilities between layers in an exascale 
system and supports dynamic and adaptive resource management and scheduling. 
It is implemented in portable C99 and is organized around a cooperative 
lightweight thread scheduler, a global address space, an active-message parcel 
transport, and a group of globally addressable local synchronization object 
classes. Internally, the infrastructure is built on scalable concurrent data 
structures to minimize shared-memory synchronization overhead. The global 
address space and parcel transport are based on the innovative Photon network 
transport library, which supports low-level access to network hardware and 
provides RDMA with remote completion events for low overhead signaling. An 
alternative ISend/IRecv network layer is included for portability, along with 
a reference MPI implementation. HPX-5 is compatible with Linux running on Intel 
x86, MAC OSX and Xeon Phi processors and various ARM core platforms (including 
both ARMv7 and ARMv8/Aarch64).

Contents
-----------

The HPX–5 distribution contains two top-level directories.

/hpx
This contains the HPX–5 interface and runtime library implementation, along with
 examples, the test suite, and third-party dependencies. The project installs 
the HPX–5 headers and the libhpx.{a,so} runtime library, along with built 
dependencies and an hpx.pc file for use with pkg-config for external projects.

/hpx-apps
This contains example applications designed to depend on an installed instance 
of HPX–5, and should serve as a usage model. In particular, it includes a 
tutorial as well as the Lulesh, Wavelet-AMR, HPCG, CoMD, and SSSP applications.

What's new in HPX-5 v4.0.0?
----------------------------
The HPX-5 runtime library is being updated to leverage C++, which simplifies 
its code base (4% fewer lines of code), provides better interoperability with 
dependencies, promotes static type safety, and promotes platform independence 
through the elimination of the libsync synchronization library and its 
associated architecture-specific functionality. In the future, this will 
assist with the development and performance of the HPX-5 C++ API. Throughout 
this effort we have paid attention to execution and compile times. Application 
performance is unchanged and the HPX-5 library compilation time (performed 
once per HPX-5 installation) has roughly doubled from 2 to 4 minutes in a 
16-core parallel build.

HPX-5 API
==========
1. Added methods to AGAS to get attributes of global blocks.
2. The hpx_run(), hpx_run_spmd(), and hpx_exit() interface has changed to support 
arbitrary epoch return types. Details are available at 
http://www.crest.iu.edu/MailArchives/hpx-users/2016/07/0077.php.
3. The hpx_run_spmd() interface requires explicitly collective use of hpx_exit() 
at each locality.

HPX Implementation
====================
1. AGAS Changes
  - Significant improvements have been made to AGAS rebalancer code.
2. Tracing infrastructure changes
  - Improvements have been made to Numpy logs -- Extended python tools to include 
    command line tool and proper modules.
3. LCO changes
  - UserLCO can now be set with a size different than the size of the state.
4. Network changes
  - Added an LRU Cache for registered chunk allocations. This reduces the amount 
    of high-frequency mmap and pin operations for large parcels. Restructured the 
    peer-to-peer data for the PWC Network.

Removed/Retired Features
---------------------------
libsync dependency has been removed

Dependencies changes
---------------------------
1. The distribution version of hwloc has been upgraded to 1.11.4
2. The distribution version of libcuckoo has been upgraded to 
   59efe01436f462e5cd3a2616b802f1b8
3. The distribution version of libfabric has been upgraded to 1.3.0
4. uthash dependency has been removed - unordered_map is being used instead of 
   uthash in the rebalancer code

Bug Fixes
-----------
1. lco_gencount unit test has been with fixed with odd number of localities > 1
2. Fixed hpx_init(NULL, NULL) segfault with --enable-debug
3. Fixed the typo in name hpx_calloc_registered
4. Fixed hpx_run epoch failures with psm/openmpi 1.10.2

Application Updates
--------------------
No application updates.

Known bugs & limitations in the release
-----------------------------------------

1. HPX-5 on Mac OS X only builds with default xcode toolchain. Use 
$ ./configure --with-hwloc=contrib --with-libffi=contrib CC=clang to configure. 
gcc installed with brew or port is not supported. We believe this is due to 
https://gcc.gnu.org/bugzilla/show_bug.cgi?format=multiple&id=60893.
2. HPX-5 on Mac OS Sierra (10.12.1) with xcode version 8.1 toolchain with 
 --enable-jemalloc results in external application execution error malloc: 
*** malloc_zone_unregister() failed. This is due to 
https://github.com/jemalloc/jemalloc/issues/420.
3. There are known regressions with TBBmalloc 4.4. Please use TBBmalloc 4.3 
or earlier.
4. The Intel toolchain on Cray platforms requires the gcc 4.8 or 4.9 compiler 
in the path (see https://www.nersc.gov/users/software/compilers/intel-fortran-c-
and-c/intel-bug-reports/c-11-header-files-appear-missing-on-edison/).
5. Clang versions prior to 3.6 (3.5.1 or earlier) contain regressions that 
trigger runtime failures in HPX.
6. The --map-by node:pe=1 flag will be incorrectly interpreted when using 
openmpi version 1.10.0, and will spawn #cores HPX-5 worker threads. Use 
--hpx-threads=1 to force 1 worker thread if necessary.
7. LULESH induces a performance regression with jemalloc, prefer tbbmalloc for 
it. When using jemalloc set MALLOC_CONF=lg_dirty_mult:-1 on the command 
line—this resolves the performance regression but may cause memory exhaustion. 
Also use hugetlbfs when available.
8. Remote hpx_lco_get/wait operations do not propagate errors correctly.
9. User registered signal handlers are overwritten by --hpx-dbg-waitonsig.
10. hpx_parcel_send and hpx_parcel_retain cannot be used in combination.
11. HPX-5 does not currently account for dynamic changes in system 
configuration. Systems that turn cores on and off may cause an unexpected 
state during startup, which will result in triggering a guarding assert check.
12. HPX-5 has to be compiled with CXXFLAGS="-O3 -fno-gcse" for aarch64 
optimized code. Optimized code with clang does not have this requirement.

General Information
---------------------

If you plan to use HPX–5, we suggest starting with the latest released
version (currently HPX–5 v4.0.0) which can be downloaded from
http://hpx.crest.iu.edu/download. If you would like to work with the
cutting edge version of HPX–5, we suggest using the the `develop`
branch at https://gitlab.crest.iu.edu/extreme/hpx. While we try to
keep the develop branch stable and usable, sometimes new bugs trick
their way into the code base - be aware!

Documentation for the latest release of HPX–5 (currently v4.0.0) and
the previous versions can be accessed at
http://hpx.crest.iu.edu/documentation. The FAQ can be found at
http://hpx.crest.iu.edu/faqs_and_tutorials.

Reporting bugs
=================

In any case, if you happen to run into problems we very much encourage and 
appreciate issue reports through the issue tracker for this Gitlab project 
(https://gitlab.crest.iu.edu/extreme/hpx/issues).  

Participate in HPX-5
======================

HPX-5 is published under a liberal open-source license and has an open, 
active, and thriving developer community. Further information can be found at 
http://hpx.crest.iu.edu.

More about HPX-5
--------------------

For more information about HPX-5, including information about the latest 
release, please check out the main https://hpx.crest.iu.edu/about. If you 
have questions or comments, the HPX-5 Developer’s Mailing List is a good 
place to send them.

Subscribe your e-mail address to be notified when new releases of HPX-5 
are released using the mailing list: HPX-5 Announcements List 
http://www.crest.iu.edu/mailman/listinfo.cgi/hpx-announce.
