HPX–5 Version 1.2.0 Release Notes
---------------------------------

Release date: 08/14/2015

Distributed under the Indiana University License.
(See accompanying file COPYING.txt) 

HPX-5 (High Performance ParalleX) provides a unified programming model
for parallel and distributed applications. It is freely available,
open source, feature complete, and performance-oriented implementation
of the ParalleX execution model. HPX-5 is a general-purpose C runtime
system for applications, targeted at conventional, widely available
architectures. We use HPX-5 for a broad range of scientific
applications, helping scientists and developers to write code that
shows better performance on irregular applications and at scale when
compared to more conventional programming models such as MPI. HPX-5
supports such applications with implementation of features like Active
Global Address Space (AGAS), ParalleX Processes, Complexes (ParalleX
Threads and Thread Management), Parcel Transport and Parcel
Management, Local Control Objects (LCOs) and Localities.

General Information
---------------------

If you plan to use HPX–5, we suggest starting with the latest released
version (currently HPX–5 v1.2.0) which can be downloaded from
https://hpx.crest.iu.edu/download. If you would like to work with the
cutting edge version of HPX–5, we suggest using the the `develop`
branch at https://gitlab.crest.iu.edu/extreme/hpx. While we try to
keep the develop branch stable and usable, sometimes new bugs trick
their way into the code base - be aware!

Documentation for the latest release of HPX–5 (currently v1.2.0) and
the previous versions can be accessed at
https://hpx.crest.iu.edu/documentation. The FAQ can be found at
https://hpx.crest.iu.edu/faqs_and_tutorials.

If you would like to work with the cutting edge version of HPX–5, we
suggest following the current health status of the develop branch at
https://gitlab.crest.iu.edu/extreme/hpx. While we try to keep the 
develop branch stable and usable, sometimes new bugs trick their way
into the code base - be aware!

Build Instructions
------------------

The detailed build instructions can be found at
[https://hpx.crest.iu.edu/faqs_and_tutorials] or
[https://hpx.crest.iu.edu/Users_Guide]. 

What's new in HPX–5 v1.2.0?
----------------------------

1. APEX - Autonomic Performance Environment for eXascale, has been integrated 
with HPX–5. APEX is both a measurement system for introspection, as well as a 
Policy Engine for modifying runtime behavior based on the observations. APEX 
is designed to combine information from the OS, runtime, hardware and 
application in order to guide policy decisions. To build HPX–5 with APEX 
support, install APEX v0.1-beta and provide --with-apex{=system, PKG}
option with configuration options.  More details can  be obtained from 
README.apex

2. Performance testing has shown that applications that link to libhpx.so 
rather than libhpx.a can be up to 20% slower due to the cost of thread-local 
variable lookups in shared libraries. Release 1.2.0 has switched the default 
configuration to build libhpx.a only. The --enable-shared configuration flag
still allows users to build libhpx.so as desired.

3. We successfully ported HPX–5 to the Xeon Phi platform. To test on MICs, load
the the appropriate intel module and add --disable-jemalloc --enable-tbbmalloc 
--with-tbbarch=mic CFLAGS="-mmic" CXXFLAGS="-mmic" CCASFLAGS="-mmic" 
--host=x86_64-k1om-linux to configure options. 

4. HPX–5 has been ported to AArch64 (new 64-bit ARM architecture, also known as
ARMv8 or ARM64).

5. We have added the PAPI (Performance Application Programming Interface) 
support to HPX for accessing hardware performance data. To build HPX–5 with 
PAPI support, install PAPI and provide --with-papi{=system, PKG} option with 
configuration options.

6. We have added support for Doug Lea's malloc for GAS allocation. Use 
--enable-dlmalloc for enabling dlmalloc. This just gives an extra comparison 
point for GAS allocation for HPX.

API Changes: Improvements/Enhancements
---------------------------------------

1. The hpx_lco_set interface has been extended with lsync and rsync 
specializations. This improves call sites where these semantics are required, 
and exposes future opportunities for HPX implementations to optimize these 
calls.

2. Interrupts may now access hpx_thread_current_* information. Interrupts 
still may not yield, set affinity, get a TLS id, or return/continue data.

Bug Fixes
------------

1. We have added the correct BTE support for uGNI. The Photon uGNI backend has 
been reworked to correctly support remote completion events, BTE threshold. PWC 
defaults have been added to HPX–5. This enables small pwc and (1-put) and BTE 
for uGNI. Photon also now configures RCQ by default for uGNI.

2. The installed hpx.pc file now provides correct flags for a --disable-shared
build.

3. The installed hpx.pc file now adds -D_POSIX_C_SOURCE=200809L to CFLAGS 
and -lrt to public libraries for Linux installation. This allows applications 
to use the HPX time interface.

4. Resolved an issue that caused hpx_thread_set_affinity() to induce a deadlock
in some circumstances.

5. Resolved an issue with --enable-hugetlbfs which would cause us to run out of
file descriptors in some circumstances.

6. Resolved an issue where HPX could inadvertently generate nested monitor 
calls, with the associated potential for HPX-induced deadlock.

7. Resolved poor ISIR termination when photon was build with PMI and MPI on 
Edison.

8. Fixed test lco_collective which was failing non-deterministically with AGAS 
enabled.

9. We have fixed free() in AGAS.

Known bugs & limitations in the release
----------------------------------------

1. AGAS and TBBMalloc require a C++11 compiler.

2. The AGAS implementation only works with the Isend/Irecv network, and is 
still considered experimental.

3. Clang versions prior to 3.6 (3.5.1 and earlier) contain regressions that 
trigger runtime failures in HPX.

4. Cray support is experimental. To run an HPX—5 application, use 
aprun -n [nodes] -N 1 -d [ppn] ./app --hpx-threads=[ppn]. 
The -d option (or equivalent) is necessary to correctly distribute worker 
threads, and the --hpx-threads option must be specified explicitly. HPX–5 
cannot be compiled using craycc.

5. The SSSP variants (delta-stepping, distributed-control, KLA) in libPXGL 
are experimental and are unlikely to run successfully at larger scales.

6. HPX–5 only runs with 1 thread by default on Jetson boards.

7. HPX_THREAD_CONTINUE does not run C++ destructors.

8. Linking tests/examples/tutorials --with-apex when apex is built statically 
fails.

9. LULESH application is killed by OOM killer for certain problem sizes on 
Edison with jemalloc.

More information
-------------------

Build Instructions
====================
The detailed build instructions can be found at 
https://hpx.crest.iu.edu/faqs_and_tutorials or 
https://hpx.crest.iu.edu//Users_Guide. 

Reporting bugs
====================
In any case, if you happen to run into problems we very much encourage and
appreciate issue reports through the issue tracker for this Gitlab project 
(https://gitlab.crest.iu.edu/extreme/hpx/issues).  

Participate in HPX–5
=====================
If you would like to help shape HPX–5, take a look at the list of ways you
can participate at http://hpx.crest.iu.edu/get-involved.

More about HPX–5
====================
For more information about HPX–5, including information about the latest 
release, please check out the main http://hpx.crest.iu.edu/about. If you 
have questions or comments, the HPX–5 Developer’s Mailing List is a good
place to send them.

Subscribe your e-mail address to be notified when new releases of HPX–5 
are released using the mailing list: HPX–5 Announcements List 
http://www.crest.iu.edu/mailman/listinfo.cgi/hpx-announce.
